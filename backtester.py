#!/usr/bin/env python3
"""
ğŸ”„ Alpha Hive å›æµ‹åé¦ˆå¾ªç¯ï¼ˆPhase 6ï¼‰

T+1 / T+7 / T+30 è‡ªåŠ¨å›çœ‹é¢„æµ‹åå·®ï¼š
1. ä¿å­˜é¢„æµ‹ï¼šæ¯æ¬¡æ‰«æåå°†èœ‚ç¾¤è¯„åˆ†+æ–¹å‘å†™å…¥ predictions è¡¨
2. å›æµ‹æ£€éªŒï¼šå®šæœŸæ£€æŸ¥åˆ°æœŸçš„é¢„æµ‹ï¼Œç”¨ yfinance è·å–å®é™…æ”¶ç›Šç‡
3. è¯„ä¼°å‡†ç¡®ç‡ï¼šæŒ‰ Agentã€ç»´åº¦ã€æ ‡çš„ç»´åº¦ç»Ÿè®¡æ–¹å‘å‡†ç¡®ç‡
4. æƒé‡è‡ªé€‚åº”ï¼šæ ¹æ®å†å²å‡†ç¡®ç‡è‡ªåŠ¨è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡
"""

import json
import sqlite3
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

try:
    import yfinance as yf
except ImportError:
    yf = None

from hive_logger import PATHS, get_logger

_log = get_logger("backtester")

DB_PATH = PATHS.db


class PredictionStore:
    """é¢„æµ‹è®°å½•å­˜å‚¨ï¼ˆSQLiteï¼‰"""

    TABLE = "predictions"

    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self._init_table()

    def _init_table(self):
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                CREATE TABLE IF NOT EXISTS {self.TABLE} (
                    id                 INTEGER PRIMARY KEY AUTOINCREMENT,
                    date               TEXT NOT NULL,
                    ticker             TEXT NOT NULL,
                    final_score        REAL NOT NULL,
                    direction          TEXT NOT NULL,
                    price_at_predict   REAL,
                    dimension_scores   TEXT,
                    agent_directions   TEXT,
                    -- T+1 å›æµ‹
                    price_t1           REAL,
                    return_t1          REAL,
                    correct_t1         INTEGER,
                    checked_t1         INTEGER DEFAULT 0,
                    -- T+7 å›æµ‹
                    price_t7           REAL,
                    return_t7          REAL,
                    correct_t7         INTEGER,
                    checked_t7         INTEGER DEFAULT 0,
                    -- T+30 å›æµ‹
                    price_t30          REAL,
                    return_t30         REAL,
                    correct_t30        INTEGER,
                    checked_t30        INTEGER DEFAULT 0,
                    created_at         TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(date, ticker)
                )
            """)
            conn.execute(f"CREATE INDEX IF NOT EXISTS idx_pred_date ON {self.TABLE}(date)")
            conn.execute(f"CREATE INDEX IF NOT EXISTS idx_pred_ticker ON {self.TABLE}(ticker)")
            conn.commit()
            conn.close()
        except (sqlite3.Error, OSError) as e:
            _log.warning("é¢„æµ‹è¡¨åˆå§‹åŒ–å¤±è´¥: %s", e)

    def save_prediction(
        self,
        ticker: str,
        final_score: float,
        direction: str,
        price: float,
        dimension_scores: Dict = None,
        agent_directions: Dict = None,
    ) -> bool:
        """ä¿å­˜ä¸€æ¡é¢„æµ‹è®°å½•"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                INSERT OR REPLACE INTO {self.TABLE}
                (date, ticker, final_score, direction, price_at_predict,
                 dimension_scores, agent_directions)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                datetime.now().strftime("%Y-%m-%d"),
                ticker,
                final_score,
                direction,
                price,
                json.dumps(dimension_scores or {}),
                json.dumps(agent_directions or {}),
            ))
            conn.commit()
            conn.close()
            return True
        except (sqlite3.Error, OSError, TypeError) as e:
            _log.warning("ä¿å­˜é¢„æµ‹å¤±è´¥ (%s): %s", ticker, e)
            return False

    def get_pending_checks(self, period: str) -> List[Dict]:
        """
        è·å–å¾…å›æµ‹çš„é¢„æµ‹è®°å½•

        period: "t1" / "t7" / "t30"
        """
        days_map = {"t1": 1, "t7": 7, "t30": 30}
        days = days_map.get(period, 7)
        checked_col = f"checked_{period}"

        # ç›®æ ‡æ—¥æœŸï¼šé¢„æµ‹æ—¥ + N å¤© <= ä»Šå¤©
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            rows = conn.execute(f"""
                SELECT * FROM {self.TABLE}
                WHERE date <= ? AND {checked_col} = 0
                ORDER BY date ASC
            """, (cutoff,)).fetchall()
            conn.close()
            return [dict(r) for r in rows]
        except (sqlite3.Error, OSError) as e:
            _log.warning("è·å–å¾…å›æµ‹è®°å½•å¤±è´¥: %s", e)
            return []

    def update_check_result(
        self, pred_id: int, period: str,
        price: float, ret: float, correct: bool
    ) -> bool:
        """æ›´æ–°å›æµ‹ç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.execute(f"""
                UPDATE {self.TABLE}
                SET price_{period} = ?, return_{period} = ?,
                    correct_{period} = ?, checked_{period} = 1
                WHERE id = ?
            """, (price, ret, 1 if correct else 0, pred_id))
            conn.commit()
            conn.close()
            return True
        except (sqlite3.Error, OSError) as e:
            _log.warning("æ›´æ–°å›æµ‹ç»“æœå¤±è´¥: %s", e)
            return False

    def get_accuracy_stats(self, period: str = "t7", days: int = 90) -> Dict:
        """
        è·å–å‡†ç¡®ç‡ç»Ÿè®¡

        è¿”å›: {
            overall_accuracy, total_checked, correct_count,
            avg_return, by_direction: {bullish: {}, bearish: {}, neutral: {}},
            by_ticker: {NVDA: {}, ...}
        }
        """
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        checked_col = f"checked_{period}"
        correct_col = f"correct_{period}"
        return_col = f"return_{period}"

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row

            # æ€»ä½“å‡†ç¡®ç‡
            row = conn.execute(f"""
                SELECT
                    COUNT(*) as total,
                    SUM({correct_col}) as correct,
                    AVG({return_col}) as avg_ret,
                    AVG(final_score) as avg_score
                FROM {self.TABLE}
                WHERE {checked_col} = 1 AND date >= ?
            """, (cutoff,)).fetchone()

            total = row["total"] or 0
            correct = row["correct"] or 0
            overall_acc = correct / total if total > 0 else 0.0

            # æŒ‰æ–¹å‘åˆ†ç»„
            by_direction = {}
            for direction in ["bullish", "bearish", "neutral"]:
                r = conn.execute(f"""
                    SELECT
                        COUNT(*) as total,
                        SUM({correct_col}) as correct,
                        AVG({return_col}) as avg_ret
                    FROM {self.TABLE}
                    WHERE {checked_col} = 1 AND direction = ? AND date >= ?
                """, (direction, cutoff)).fetchone()
                t = r["total"] or 0
                by_direction[direction] = {
                    "total": t,
                    "correct": r["correct"] or 0,
                    "accuracy": (r["correct"] or 0) / t if t > 0 else 0.0,
                    "avg_return": round(r["avg_ret"] or 0, 2),
                }

            # æŒ‰æ ‡çš„åˆ†ç»„
            by_ticker = {}
            rows = conn.execute(f"""
                SELECT
                    ticker,
                    COUNT(*) as total,
                    SUM({correct_col}) as correct,
                    AVG({return_col}) as avg_ret,
                    AVG(final_score) as avg_score
                FROM {self.TABLE}
                WHERE {checked_col} = 1 AND date >= ?
                GROUP BY ticker
                ORDER BY total DESC
            """, (cutoff,)).fetchall()
            for r in rows:
                t = r["total"] or 0
                by_ticker[r["ticker"]] = {
                    "total": t,
                    "correct": r["correct"] or 0,
                    "accuracy": (r["correct"] or 0) / t if t > 0 else 0.0,
                    "avg_return": round(r["avg_ret"] or 0, 2),
                    "avg_score": round(r["avg_score"] or 0, 1),
                }

            conn.close()

            return {
                "period": period,
                "days_window": days,
                "overall_accuracy": round(overall_acc, 3),
                "total_checked": total,
                "correct_count": correct,
                "avg_return": round(row["avg_ret"] or 0, 3),
                "avg_score": round(row["avg_score"] or 0, 1),
                "by_direction": by_direction,
                "by_ticker": by_ticker,
            }
        except (sqlite3.Error, OSError, KeyError, TypeError) as e:
            _log.warning("è·å–å‡†ç¡®ç‡ç»Ÿè®¡å¤±è´¥: %s", e)
            return {"overall_accuracy": 0, "total_checked": 0}

    def get_all_predictions(self, days: int = 30) -> List[Dict]:
        """è·å–æœ€è¿‘ N å¤©æ‰€æœ‰é¢„æµ‹"""
        cutoff = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            rows = conn.execute(f"""
                SELECT * FROM {self.TABLE}
                WHERE date >= ? ORDER BY date DESC, ticker
            """, (cutoff,)).fetchall()
            conn.close()
            return [dict(r) for r in rows]
        except (sqlite3.Error, OSError) as e:
            _log.warning("è·å–é¢„æµ‹åˆ—è¡¨å¤±è´¥: %s", e)
            return []


class Backtester:
    """
    å›æµ‹å¼•æ“ - è‡ªåŠ¨æ£€éªŒé¢„æµ‹å‡†ç¡®ç‡

    å·¥ä½œæµï¼š
    1. save_predictions()ï¼šæ‰«æç»“æŸåä¿å­˜æ‰€æœ‰é¢„æµ‹
    2. run_backtest()ï¼šæ£€æŸ¥åˆ°æœŸçš„é¢„æµ‹ï¼Œè·å–å®é™…ä»·æ ¼ï¼Œè®¡ç®—æ”¶ç›Šç‡
    3. print_report()ï¼šè¾“å‡ºå‡†ç¡®ç‡æŠ¥å‘Š
    4. adapt_weights()ï¼šæ ¹æ®å‡†ç¡®ç‡è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡
    """

    def __init__(self, db_path: str = DB_PATH):
        self.store = PredictionStore(db_path)

    # ==================== ä¿å­˜é¢„æµ‹ ====================

    def save_predictions(self, swarm_results: Dict) -> int:
        """
        å°†èœ‚ç¾¤æ‰«æç»“æœä¿å­˜ä¸ºé¢„æµ‹è®°å½•

        Args:
            swarm_results: {ticker: {final_score, direction, dimension_scores, ...}}

        Returns:
            ä¿å­˜çš„è®°å½•æ•°
        """
        saved = 0
        for ticker, data in swarm_results.items():
            if not isinstance(data, dict):
                continue

            # æ”¶é›†å„ Agent çš„æ–¹å‘ï¼ˆä» QueenDistiller çš„ agent_directions å­—æ®µï¼‰
            agent_dirs = data.get("agent_directions", {})

            # è·å–é¢„æµ‹æ—¶çš„ä»·æ ¼
            price = 0.0
            try:
                if yf:
                    stock = yf.Ticker(ticker)
                    price = stock.fast_info.get("lastPrice", 0)
            except (ConnectionError, TimeoutError, OSError, ValueError, KeyError, AttributeError) as e:
                _log.debug("Price fetch failed for %s: %s", ticker, e)

            ok = self.store.save_prediction(
                ticker=ticker,
                final_score=data.get("final_score", 5.0),
                direction=data.get("direction", "neutral"),
                price=price,
                dimension_scores=data.get("dimension_scores"),
                agent_directions=agent_dirs,
            )
            if ok:
                saved += 1

        return saved

    # ==================== æ‰§è¡Œå›æµ‹ ====================

    def run_backtest(self) -> Dict:
        """
        æ‰§è¡Œå›æµ‹æ£€éªŒï¼šæ£€æŸ¥æ‰€æœ‰åˆ°æœŸçš„é¢„æµ‹

        è¿”å›: {t1: {checked, correct}, t7: {...}, t30: {...}}
        """
        # å›æµ‹æ£€éªŒ
        results = {}

        for period in ["t1", "t7", "t30"]:
            pending = self.store.get_pending_checks(period)
            if not pending:
                results[period] = {"checked": 0, "correct": 0, "skipped": 0}
                continue

            days_map = {"t1": 1, "t7": 7, "t30": 30}
            days = days_map[period]
            checked = 0
            correct = 0
            skipped = 0

            # {period.upper()} å›æµ‹

            for pred in pending:
                ticker = pred["ticker"]
                predict_date = pred["date"]
                predict_price = pred.get("price_at_predict", 0)
                direction = pred["direction"]

                if not predict_price or predict_price <= 0:
                    skipped += 1
                    continue

                # è·å– T+N æ—¥çš„å®é™…ä»·æ ¼
                actual_price = self._get_price_at_date(
                    ticker, predict_date, days
                )

                if actual_price is None or actual_price <= 0:
                    skipped += 1
                    continue

                # è®¡ç®—æ”¶ç›Šç‡
                ret = (actual_price - predict_price) / predict_price * 100

                # åˆ¤æ–­æ–¹å‘æ˜¯å¦æ­£ç¡®
                is_correct = self._check_direction(direction, ret)

                self.store.update_check_result(
                    pred["id"], period, actual_price, round(ret, 3), is_correct
                )

                checked += 1
                if is_correct:
                    correct += 1

            results[period] = {
                "checked": checked,
                "correct": correct,
                "skipped": skipped,
                "accuracy": correct / checked if checked > 0 else 0,
            }

            pass  # å‡†ç¡®ç‡å·²è®¡ç®—

        return results

    def _get_price_at_date(
        self, ticker: str, predict_date: str, days_ahead: int
    ) -> Optional[float]:
        """è·å–é¢„æµ‹æ—¥å N å¤©çš„æ”¶ç›˜ä»·"""
        if yf is None:
            return None

        try:
            target_date = datetime.strptime(predict_date, "%Y-%m-%d") + timedelta(days=days_ahead)
            # å‘åå¤šå–å‡ å¤©ä»¥è¦†ç›–å‘¨æœ«/å‡æ—¥
            end_date = target_date + timedelta(days=5)

            stock = yf.Ticker(ticker)
            hist = stock.history(
                start=target_date.strftime("%Y-%m-%d"),
                end=end_date.strftime("%Y-%m-%d"),
            )

            if hist.empty:
                return None

            # å–ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
            return float(hist["Close"].iloc[0])

        except (ConnectionError, TimeoutError, OSError, ValueError, KeyError) as e:
            _log.debug("Future price fetch failed for %s +%dd: %s", ticker, days_ahead, e)
            return None

    def _check_direction(self, direction: str, actual_return: float) -> bool:
        """
        æ£€æŸ¥é¢„æµ‹æ–¹å‘æ˜¯å¦æ­£ç¡®

        è§„åˆ™:
        - bullish: å®é™…æ”¶ç›Š > -1%ï¼ˆå…è®¸å°å¹…å›è°ƒï¼‰
        - bearish: å®é™…æ”¶ç›Š < +1%
        - neutral: å®é™…æ”¶ç›Šåœ¨ Â±3% å†…
        """
        if direction == "bullish":
            return actual_return > -1.0
        elif direction == "bearish":
            return actual_return < 1.0
        else:  # neutral
            return abs(actual_return) < 3.0

    # ==================== å‡†ç¡®ç‡æŠ¥å‘Š ====================

    def print_report(self, days: int = 90) -> str:
        """è¾“å‡ºå®Œæ•´çš„å‡†ç¡®ç‡æŠ¥å‘Š"""
        lines = []
        lines.append("\n" + "=" * 70)
        lines.append("  ğŸ“Š Alpha Hive å›æµ‹å‡†ç¡®ç‡æŠ¥å‘Š")
        lines.append(f"  ğŸ“… ç»Ÿè®¡çª—å£ï¼šæœ€è¿‘ {days} å¤©")
        lines.append("=" * 70)

        for period in ["t1", "t7", "t30"]:
            label = {"t1": "T+1ï¼ˆæ¬¡æ—¥ï¼‰", "t7": "T+7ï¼ˆä¸€å‘¨ï¼‰", "t30": "T+30ï¼ˆä¸€æœˆï¼‰"}
            stats = self.store.get_accuracy_stats(period, days)

            total = stats.get("total_checked", 0)
            if total == 0:
                lines.append(f"\n  [{label[period]}] æš‚æ— æ•°æ®")
                continue

            acc = stats["overall_accuracy"]
            avg_ret = stats["avg_return"]
            lines.append(f"\n  [{label[period]}]")
            lines.append(f"  æ€»ä½“å‡†ç¡®ç‡: {acc*100:.1f}% ({stats['correct_count']}/{total})")
            lines.append(f"  å¹³å‡æ”¶ç›Šç‡: {avg_ret:+.2f}%")
            lines.append(f"  å¹³å‡è¯„åˆ†: {stats.get('avg_score', 0):.1f}/10")

            # æŒ‰æ–¹å‘
            by_dir = stats.get("by_direction", {})
            if by_dir:
                lines.append("  æŒ‰æ–¹å‘:")
                for d, info in by_dir.items():
                    if info["total"] > 0:
                        label_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(d, d)
                        lines.append(
                            f"    {label_cn}: {info['accuracy']*100:.0f}% "
                            f"({info['correct']}/{info['total']}) "
                            f"å¹³å‡æ”¶ç›Š {info['avg_return']:+.2f}%"
                        )

            # æŒ‰æ ‡çš„
            by_ticker = stats.get("by_ticker", {})
            if by_ticker:
                lines.append("  æŒ‰æ ‡çš„:")
                for t, info in sorted(by_ticker.items(), key=lambda x: x[1]["total"], reverse=True):
                    lines.append(
                        f"    {t}: {info['accuracy']*100:.0f}% "
                        f"({info['correct']}/{info['total']}) "
                        f"å¹³å‡æ”¶ç›Š {info['avg_return']:+.2f}%"
                    )

        # æœ€è¿‘é¢„æµ‹åˆ—è¡¨
        recent = self.store.get_all_predictions(days=14)
        if recent:
            lines.append(f"\n  æœ€è¿‘é¢„æµ‹è®°å½• ({len(recent)} æ¡):")
            lines.append(f"  {'æ—¥æœŸ':<12} {'æ ‡çš„':<6} {'è¯„åˆ†':>5} {'æ–¹å‘':<8} "
                         f"{'ä»·æ ¼':>8} {'T+1':>8} {'T+7':>8} {'T+30':>8}")
            lines.append("  " + "-" * 66)

            for p in recent[:20]:
                t1_str = f"{p['return_t1']:+.1f}%" if p.get("checked_t1") else "å¾…æ£€"
                t7_str = f"{p['return_t7']:+.1f}%" if p.get("checked_t7") else "å¾…æ£€"
                t30_str = f"{p['return_t30']:+.1f}%" if p.get("checked_t30") else "å¾…æ£€"
                dir_cn = {"bullish": "çœ‹å¤š", "bearish": "çœ‹ç©º", "neutral": "ä¸­æ€§"}.get(
                    p["direction"], p["direction"]
                )
                lines.append(
                    f"  {p['date']:<12} {p['ticker']:<6} "
                    f"{p['final_score']:5.1f} {dir_cn:<8} "
                    f"${p.get('price_at_predict', 0):7.1f} "
                    f"{t1_str:>8} {t7_str:>8} {t30_str:>8}"
                )

        lines.append("\n" + "=" * 70)

        report = "\n".join(lines)
        _log.info(report)
        return report

    # ==================== æƒé‡è‡ªé€‚åº” ====================

    def adapt_weights(self, min_samples: int = 10) -> Optional[Dict]:
        """
        æ ¹æ® T+7 å‡†ç¡®ç‡è‡ªåŠ¨è°ƒæ•´ 5 ç»´å…¬å¼æƒé‡

        è§„åˆ™ï¼š
        - æ”¶é›†æ¯ä¸ªç»´åº¦ï¼ˆsignal, catalyst, sentiment, odds, risk_adjï¼‰
          å¯¹åº” Agent çš„ T+7 æ–¹å‘å‡†ç¡®ç‡
        - å‡†ç¡®ç‡é«˜çš„ç»´åº¦è·å¾—æ›´é«˜æƒé‡
        - æƒé‡å½’ä¸€åŒ–ï¼šæ€»å’Œ = 1.0
        - æœ€ä½æ ·æœ¬æ•°è¦æ±‚ï¼šmin_samples

        è¿”å›: {dimension: new_weight} æˆ– Noneï¼ˆæ ·æœ¬ä¸è¶³ï¼‰
        """
        # Agent â†’ ç»´åº¦æ˜ å°„
        agent_dim_map = {
            "ScoutBeeNova": "signal",
            "OracleBeeEcho": "odds",
            "BuzzBeeWhisper": "sentiment",
            "ChronosBeeHorizon": "catalyst",
            "GuardBeeSentinel": "risk_adj",
        }

        # é»˜è®¤æƒé‡
        default_weights = {
            "signal": 0.30,
            "catalyst": 0.20,
            "sentiment": 0.20,
            "odds": 0.15,
            "risk_adj": 0.15,
        }

        # è·å–æ¯ä¸ªç»´åº¦çš„å‡†ç¡®ç‡
        dim_accuracy = {}
        total_samples = 0

        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.row_factory = sqlite3.Row

            for agent_name, dim in agent_dim_map.items():
                # ä» agent_directions JSON ä¸­æå–å„ Agent çš„æ–¹å‘é¢„æµ‹
                # ç„¶åä¸å®é™…æ”¶ç›Šæ¯”è¾ƒ
                rows = conn.execute(f"""
                    SELECT
                        agent_directions, return_t7, direction
                    FROM {PredictionStore.TABLE}
                    WHERE checked_t7 = 1 AND agent_directions IS NOT NULL
                    AND date >= ?
                """, ((datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d"),)).fetchall()

                correct = 0
                checked = 0
                for row in rows:
                    try:
                        dirs = json.loads(row["agent_directions"])
                        agent_dir = dirs.get(agent_name)
                        if not agent_dir:
                            continue
                        ret = row["return_t7"]
                        if ret is None:
                            continue

                        checked += 1
                        if self._check_direction(agent_dir, ret):
                            correct += 1
                    except (json.JSONDecodeError, KeyError, TypeError, ValueError) as e:
                        _log.debug("Agent direction parse error: %s", e)
                        continue

                if checked >= min_samples:
                    dim_accuracy[dim] = correct / checked
                    total_samples += checked
                else:
                    dim_accuracy[dim] = 0.5  # æ ·æœ¬ä¸è¶³æ—¶ç”¨é»˜è®¤ 50%

            conn.close()

        except (sqlite3.Error, OSError, json.JSONDecodeError, KeyError, TypeError) as e:
            _log.warning("æƒé‡è‡ªé€‚åº”å¤±è´¥: %s", e)
            return None

        if total_samples < min_samples:
            pass  # æ ·æœ¬ä¸è¶³ï¼Œä¿æŒé»˜è®¤
            return None

        # è®¡ç®—æ–°æƒé‡ï¼šå‡†ç¡®ç‡^2 å½’ä¸€åŒ–ï¼ˆæ”¾å¤§å·®å¼‚ï¼‰
        raw = {dim: max(0.05, acc ** 2) for dim, acc in dim_accuracy.items()}
        total_raw = sum(raw.values())
        new_weights = {dim: round(v / total_raw, 3) for dim, v in raw.items()}

        # å¹³æ»‘è¿‡æ¸¡ï¼š80% æ–°æƒé‡ + 20% é»˜è®¤æƒé‡ï¼ˆé˜²æ­¢å‰§çƒˆæ³¢åŠ¨ï¼‰
        smoothed = {}
        for dim in default_weights:
            old_w = default_weights[dim]
            new_w = new_weights.get(dim, old_w)
            smoothed[dim] = round(old_w * 0.2 + new_w * 0.8, 3)

        # å†æ¬¡å½’ä¸€åŒ–
        s = sum(smoothed.values())
        smoothed = {dim: round(v / s, 3) for dim, v in smoothed.items()}

        # æƒé‡è‡ªé€‚åº”å®Œæˆ

        # æŒä¹…åŒ–åˆ°æ•°æ®åº“
        self._save_adapted_weights(smoothed, dim_accuracy, total_samples)

        return smoothed

    def _save_adapted_weights(
        self, weights: Dict, accuracy: Dict, samples: int
    ):
        """å°†è‡ªé€‚åº”æƒé‡æŒä¹…åŒ–åˆ° SQLite"""
        try:
            conn = sqlite3.connect(self.store.db_path)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS adapted_weights (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    date TEXT NOT NULL,
                    weights TEXT NOT NULL,
                    accuracy TEXT NOT NULL,
                    sample_count INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.execute("""
                INSERT INTO adapted_weights (date, weights, accuracy, sample_count)
                VALUES (?, ?, ?, ?)
            """, (
                datetime.now().strftime("%Y-%m-%d"),
                json.dumps(weights),
                json.dumps({k: round(v, 3) for k, v in accuracy.items()}),
                samples,
            ))
            conn.commit()
            conn.close()
        except (sqlite3.Error, OSError, TypeError) as e:
            _log.warning("ä¿å­˜è‡ªé€‚åº”æƒé‡å¤±è´¥: %s", e)

    @staticmethod
    def load_adapted_weights(db_path: str = DB_PATH) -> Optional[Dict]:
        """
        åŠ è½½æœ€è¿‘çš„è‡ªé€‚åº”æƒé‡ï¼ˆä¾› QueenDistiller ä½¿ç”¨ï¼‰

        Returns:
            {signal: 0.xx, catalyst: 0.xx, ...} æˆ– None
        """
        try:
            conn = sqlite3.connect(db_path)
            row = conn.execute("""
                SELECT weights, sample_count FROM adapted_weights
                ORDER BY created_at DESC LIMIT 1
            """).fetchone()
            conn.close()

            if row and row[1] >= 5:  # è‡³å°‘ 5 ä¸ªæ ·æœ¬æ‰ä½¿ç”¨
                weights = json.loads(row[0])
                return weights
            return None
        except (sqlite3.Error, OSError, json.JSONDecodeError, KeyError) as e:
            _log.debug("Adapted weights load failed: %s", e)
            return None


# ==================== ä¾¿æ·å‡½æ•° ====================

def run_full_backtest(swarm_results: Dict = None) -> Dict:
    """
    æ‰§è¡Œå®Œæ•´å›æµ‹æµç¨‹

    1. ä¿å­˜æ–°é¢„æµ‹ï¼ˆå¦‚æœ‰ï¼‰
    2. æ£€æŸ¥åˆ°æœŸé¢„æµ‹
    3. è¾“å‡ºæŠ¥å‘Š
    4. å°è¯•æƒé‡è‡ªé€‚åº”

    è¿”å›: {backtest_results, accuracy_stats, adapted_weights}
    """
    bt = Backtester()

    # 1. ä¿å­˜æ–°é¢„æµ‹
    if swarm_results:
        bt.save_predictions(swarm_results)

    # 2. å›æµ‹åˆ°æœŸé¢„æµ‹
    backtest_results = bt.run_backtest()

    # 3. å‡†ç¡®ç‡æŠ¥å‘Š
    bt.print_report()

    # 4. æƒé‡è‡ªé€‚åº”
    adapted = bt.adapt_weights(min_samples=10)

    return {
        "backtest_results": backtest_results,
        "adapted_weights": adapted,
    }
